{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f0c5a97b",
   "metadata": {},
   "source": [
    "#coding diary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559864e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 2(10-17th, 2021): Creating DMC(Duff moisture content) mode\n",
    "\n",
    "\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def daylength(dayOfYear, lat):\n",
    "    \"\"\"Computes the length of the day (the time between sunrise and\n",
    "    sunset) given the day of the year and latitude of the location.\n",
    "    Function uses the Brock model for the computations.\n",
    "    For more information see, for example,\n",
    "    Forsythe et al., \"A model comparison for daylength as a\n",
    "    function of latitude and day of year\", Ecological Modelling,\n",
    "    1995.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dayOfYear : int\n",
    "        The day of the year. 1 corresponds to 1st of January\n",
    "        and 365 to 31st December (on a non-leap year).\n",
    "    lat : float\n",
    "        Latitude of the location in degrees. Positive values\n",
    "        for north and negative for south.\n",
    "    Returns\n",
    "    -------\n",
    "    d : float\n",
    "        Daylength in hours.\n",
    "    \"\"\"\n",
    "    latInRad = np.deg2rad(lat)\n",
    "    declinationOfEarth = 23.45*np.sin(np.deg2rad(360.0*(283.0+dayOfYear)/365.0))\n",
    "    if -np.tan(latInRad) * np.tan(np.deg2rad(declinationOfEarth)) <= -1.0:\n",
    "        return 24.0\n",
    "    elif -np.tan(latInRad) * np.tan(np.deg2rad(declinationOfEarth)) >= 1.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        hourAngle = np.rad2deg(np.arccos(-np.tan(latInRad) * np.tan(np.deg2rad(declinationOfEarth))))\n",
    "        return 2.0*hourAngle/15.0\n",
    "\n",
    "#DMC Model\n",
    "\n",
    "def DMC(TEMP,RH,RAIN,DMCPrev,dayOfYear, lat):\n",
    "    '''Calculates today's Duff Moisture Code\n",
    "Parameters:\n",
    "    TEMP is the 12:00 LST temperature in degrees celsius\n",
    "    RH is the 12:00 LST relative humidity in %\n",
    "    RAIN is the 24-hour accumulated rainfall in mm, calculated at 12:00 LST\n",
    "    DMCstart is the start dmc\n",
    "    DMCPrev is the prevvious day's DMC\n",
    "    lat is the latitude in decimal degrees of the location for which calculations are being made\n",
    "    dayOfYear is the day of the year(int).\n",
    "\n",
    "    DMC(17,42,0,6,94,45.98)'''\n",
    "    RH = min(100.0,RH)\n",
    "    if RAIN > 1.5:\n",
    "        re = 0.92 * RAIN - 1.27\n",
    "\n",
    "        mo = 20.0 + math.exp(5.6348 - DMCPrev / 43.43)\n",
    "\n",
    "        if DMCPrev <= 33.0:\n",
    "            b = 100.0 / (0.35 + 0.3 * DMCPrev)\n",
    "        else:\n",
    "            if DMCPrev <= 65.0:\n",
    "                b = 14.0 - 1.3 * math.log(DMCPrev)\n",
    "            else:\n",
    "                b = 6.2 * math.log(DMCPrev) - 17.2\n",
    "        \n",
    "        mr = mo + 1000.0 * re / (48.77 + b * re)\n",
    "\n",
    "        pr = 244.72 - 43.43 * math.log(mr - 20.0)\n",
    "\n",
    "        if pr > 0.0:\n",
    "            DMCPrev = pr\n",
    "        else:\n",
    "            DMCPrev = 0.0\n",
    "\n",
    "    if TEMP > -1.1:\n",
    "        d1 = daylength(dayOfYear, lat)\n",
    "\n",
    "        k = 1.894 * (TEMP + 1.1) * (100.0 - RH) * d1 * 0.000001\n",
    "\n",
    "    else:\n",
    "        k = 0.0\n",
    "\n",
    "    return DMCPrev + 100.0 * k\n",
    "\n",
    "#data combining of stie data(TEMP,RH) + atmosphere data(Rain)\n",
    "#site weather station( North Fraser )\n",
    "fields =[\"TIMESTAMP\",\"AirTC\",\"RH\"]\n",
    "df=pd.read_csv(\"NF_ws.csv\",skipinitialspace=True,usecols=fields)\n",
    "time_need=[\"12:00\"]\n",
    "b = [any(i.lower() in j.lower() for i in time_need) for j in df[\"TIMESTAMP\"].values]\n",
    "df=df[b]\n",
    "date=df[\"TIMESTAMP\"]\n",
    "\n",
    "#add day of year \n",
    "date = pd.to_datetime(date, format='%Y%m%d %H:%M:%S',errors='coerce')\n",
    "dayOfYear =date.dt.dayofyear\n",
    "\n",
    "df['dayOfYear'] = dayOfYear\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#PG airport weather station\n",
    "fields1 =[\"Date/Time\",\"Total Precip (mm)\"]\n",
    "df1=pd.read_csv(\"pgap.csv\",skipinitialspace=True,usecols=fields1)\n",
    "df1.fillna(0, inplace=True)\n",
    "\n",
    "date1=pd.to_datetime(df1[\"Date/Time\"])\n",
    "a=(date1>='2021-06-15')&(date1<='2021-09-30')\n",
    "newdf1=df1.loc[a]\n",
    "newdf1.reset_index(drop=True, inplace=True)\n",
    "print(newdf1)\n",
    "\n",
    "#combine them together \n",
    "df[\"Pg_ar_Rain\"]=newdf1[\"Total Precip (mm)\"]\n",
    "\n",
    "    \n",
    "#weather condition> DMC\n",
    "DMCPrev=10 #assume numebr as a start \n",
    "count=0#data frame length \n",
    "Temp=df[\"AirTC\"]\n",
    "RH=df[\"RH\"]\n",
    "RAIN=df[\"Pg_ar_Rain\"]\n",
    "dayOfYear=df[\"dayOfYear\"]\n",
    "DMC_List=[]\n",
    "while count<108:\n",
    "    DMCPrev=DMC(Temp[count],RH[count],RAIN[count],DMCPrev,dayOfYear[count], 54)\n",
    "    DMC_List.append(DMCPrev)\n",
    "    count+=1\n",
    "    \n",
    "# plot \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(DMC_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 3(17th-24th)\n",
    "FFMC model Build up\n",
    "#FFMC model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "def FFMC(TEMP,RH,WIND,RAIN,FFMCPrev):\n",
    "    '''Calculates today's Fine Fuel Moisture Code\n",
    "Parameters:\n",
    "    TEMP is the 12:00 LST temperature in degrees celsius\n",
    "    RH is the 12:00 LST relative humidity in %\n",
    "    RAIN is the 24-hour accumulated rainfall in mm, calculated at 12:00 LST\n",
    "    FFMCPrev is the previous day's FFMC\n",
    "\n",
    "    FFMC(17,42,25,0,85) = 87.692980092774448'''\n",
    "\n",
    "    RH = min(100.0,RH)\n",
    "    mo = 147.2 * (101.0 - FFMCPrev) / (59.5 + FFMCPrev)\n",
    "\n",
    "    if RAIN > .5:\n",
    "        rf = RAIN - .5\n",
    "\n",
    "        if mo <= 150.0:\n",
    "            mr = mo + \\\n",
    "                 42.5 * rf * math.exp(-100.0 / (251.0 - mo)) * (1.0-math.exp(-6.93 / rf))\n",
    "        else:\n",
    "\n",
    "            mr = mo + \\\n",
    "                 42.5 * rf * math.exp(-100.0 / (251.0 - mo)) * (1.0-math.exp(-6.93 / rf)) + \\\n",
    "                 0.0015 * pow(mo - 150.0, 2) * pow(rf, .5)\n",
    "\n",
    "        if mr > 250.0:\n",
    "            mr = 250.0\n",
    "\n",
    "        mo=mr\n",
    "\n",
    "    ed = 0.942 * pow(RH, 0.679) + \\\n",
    "         11.0 * math.exp((RH - 100.0) / 10.0) + 0.18 * (21.1 - TEMP) * (1.0 - math.exp(-0.115 * RH))\n",
    "\n",
    "    if mo > ed:\n",
    "        ko = 0.424 * (1.0 - pow(RH / 100.0, 1.7)) + \\\n",
    "             0.0694 * pow(WIND, .5) * (1.0 - pow(RH / 100.0, 8))\n",
    "\n",
    "        kd = ko * 0.581 * math.exp(0.0365 * TEMP)\n",
    "\n",
    "        m = ed + (mo - ed) * pow(10.0,-kd)\n",
    "\n",
    "    else:\n",
    "        ew = 0.618 * pow(RH,0.753) + \\\n",
    "             10.0 * math.exp((RH - 100.0) / 10.0) + \\\n",
    "             0.18 * (21.1 - TEMP) * (1.0 - math.exp(-0.115 * RH))\n",
    "        if mo < ew:\n",
    "            k1 = 0.424 * (1.0 - pow((100.0 - RH) / 100.0, 1.7)) + \\\n",
    "                 0.0694 * pow(WIND, .5) * (1.0 - pow((100.0 - RH) / 100.0, 8))\n",
    "\n",
    "            kw = k1 * 0.581 * math.exp(0.0365 * TEMP)\n",
    "\n",
    "            m = ew - (ew - mo) * pow(10.0, -kw)\n",
    "        else:\n",
    "            m = mo\n",
    "    return 59.5 * (250.0 - m) / (147.2 + m)\n",
    "\n",
    "#data combining of stie data(TEMP,RH) + atmosphere data(Rain)\n",
    "#site weather station( North Fraser )\n",
    "fields =[\"TIMESTAMP\",\"AirTC\",\"RH\",\"Wind_Speed_m_s\"]\n",
    "df=pd.read_csv(\"NF_ws.csv\",skipinitialspace=True,usecols=fields)\n",
    "time_need=[\"12:00\"]\n",
    "b = [any(i.lower() in j.lower() for i in time_need) for j in df[\"TIMESTAMP\"].values]\n",
    "df=df[b]\n",
    "date=df[\"TIMESTAMP\"]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#PG airport weather station\n",
    "fields1 =[\"Date/Time\",\"Total Precip (mm)\"]\n",
    "df1=pd.read_csv(\"pgap.csv\",skipinitialspace=True,usecols=fields1)\n",
    "df1.fillna(0, inplace=True)\n",
    "\n",
    "date1=pd.to_datetime(df1[\"Date/Time\"])\n",
    "a=(date1>='2021-06-15')&(date1<='2021-09-30')\n",
    "newdf1=df1.loc[a]\n",
    "newdf1.reset_index(drop=True, inplace=True)\n",
    "print(newdf1)\n",
    "\n",
    "#combine them together \n",
    "df[\"Pg_ar_Rain\"]=newdf1[\"Total Precip (mm)\"]\n",
    "\n",
    "\n",
    "\n",
    "#re-number the index\n",
    "\n",
    "print(df)\n",
    "#combine site +atomphsere \n",
    "\n",
    "\n",
    "#weather condition> FFMC\n",
    "FFMCPrev=50 #assume numebr as a start \n",
    "count=0#data frame length \n",
    "Temp=df[\"AirTC\"]\n",
    "RH=df[\"RH\"]\n",
    "RAIN=df[\"Pg_ar_Rain\"]\n",
    "Wind=df[\"Wind_Speed_m_s\"]\n",
    "FFMC_List=[]\n",
    "while count<108:\n",
    "    FFMCPrev=FFMC(Temp[count],RH[count],Wind[count]/3.6,RAIN[count],FFMCPrev)\n",
    "    FFMC_List.append(147.2*(101-FFMCPrev)/(59.2+FFMCPrev))\n",
    "    count+=1\n",
    "\n",
    "plt.plot(FFMC_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 4(24th-31st)\n",
    "#combining of field data+ emperical data \n",
    "df[\"FMC\"]=FFMC_List\n",
    "fields2=[\"Location\",\"Stand_Type\",\"Fuel_Type\",\"Date_Collected\",\"Moisture_Percent\"]\n",
    "df2=pd.read_csv(\"2021PgFuel.csv\",skipinitialspace=True,usecols=fields2)\n",
    "location=df2[\"Location\"]==\"NFraser\"\n",
    "fuel=df2[\"Fuel_Type\"]==\"fines\"\n",
    "stand=df2[\"Stand_Type\"]==\"open\"\n",
    "df2=df2[location&fuel&stand]\n",
    "df3=df2.groupby(pd.to_datetime(df2[\"Date_Collected\"])).mean()\n",
    "df3 = df3.reset_index()\n",
    "df3[\"Date_Collected\"]=df3[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "a=pd.to_datetime(df[\"TIMESTAMP\"])\n",
    "a.apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "df[\"TIMESTAMP\"]=a\n",
    "df[\"TIMESTAMP\"]=df[\"TIMESTAMP\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "final=pd.merge(left=df,right=df3,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "#calculate the difference\n",
    "final[\"Difference\"]=final[\"FMC\"]-final[\"Moisture_Percent\"]\n",
    "plt.plot(final[\"FMC\"],final[\"Moisture_Percent\"],\"o\")\n",
    "#add a 1:1 line in the plot\n",
    "x=np.linspace(0,170)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"Fine Fuel MC results comparision at NF, open, 12 couples\")\n",
    "\n",
    "#calculate statistic results out \n",
    "MSE = np.square(np.subtract(final[\"Moisture_Percent\"],final[\"FMC\"])).mean() \n",
    " \n",
    "RMSE = round(math.sqrt(MSE),2)\n",
    "print(\"RMSE = \",RMSE)\n",
    "\n",
    "#using IQR method to do exclusive the outlayers \n",
    "Q1 = final[\"Difference\"].quantile(0.25)\n",
    "Q3= final[\"Difference\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "final= final[~((final[\"Difference\"] < (Q1 - 1.5 * IQR)) |(final[\"Difference\"] > (Q3 + 1.5 * IQR)))]\n",
    "plt.plot(final[\"FMC\"],final[\"Moisture_Percent\"],\"o\")\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"Fine Fuel MC results comparision at NF, open\")\n",
    "x=np.linspace(0,45)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "MSE = np.square(np.subtract(final[\"Moisture_Percent\"],final[\"FMC\"])).mean() \n",
    " \n",
    "RMSE = round(math.sqrt(MSE),2)\n",
    "print(\"Root Mean Square Error:\\n\")\n",
    "print(RMSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# week 4(24th-31st)\n",
    "\n",
    "#weather condition> DMC>FMC\n",
    "from math import e\n",
    "DMCPrev=10 #assume numebr as a start \n",
    "count=0#data frame length \n",
    "Temp=df[\"AirTC\"]\n",
    "RH=df[\"RH\"]\n",
    "RAIN=df[\"Pg_ar_Rain\"]\n",
    "dayOfYear=df[\"dayOfYear\"]\n",
    "DMC_List=[]\n",
    "while count<108:\n",
    "    DMCPrev=DMC(Temp[count],RH[count],RAIN[count],DMCPrev,dayOfYear[count], 54)\n",
    "    #what is appened downbelow is actuall FMC\n",
    "    DMC_List.append(20+e**((DMCPrev-244.72)/(-43.43)))\n",
    "    count+=1\n",
    "df[\"Dmc\"]=DMC_List\n",
    "print (df)\n",
    "\n",
    "#combining of field data +emperical data for Duff\n",
    "fields2=[\"Location\",\"Stand_Type\",\"Fuel_Type\",\"Date_Collected\",\"Moisture_Percent\"]\n",
    "df2=pd.read_csv(\"2021PgFuel.csv\",skipinitialspace=True,usecols=fields2)\n",
    "location=df2[\"Location\"]==\"NFraser\"\n",
    "fuel=df2[\"Fuel_Type\"]==\"duff\"\n",
    "stand=df2[\"Stand_Type\"]==\"open\"\n",
    "df2=df2[location&fuel&stand]\n",
    "df3=df2.groupby(pd.to_datetime(df2[\"Date_Collected\"])).mean()\n",
    "df3 = df3.reset_index()\n",
    "df3[\"Date_Collected\"]=df3[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "a=pd.to_datetime(df[\"TIMESTAMP\"])\n",
    "a.apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "df[\"TIMESTAMP\"]=a\n",
    "df[\"TIMESTAMP\"]=df[\"TIMESTAMP\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "final=pd.merge(left=df,right=df3,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "#apply difference to compare\n",
    "final[\"Difference\"]=final[\"Dmc\"]-final[\"Moisture_Percent\"]\n",
    "plt.plot(final[\"Dmc\"],final[\"Moisture_Percent\"],\"o\")\n",
    "x=np.linspace(0,300)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"Duff MC results comparision at NF, open\")\n",
    "\n",
    "MSE = np.square(np.subtract(final[\"Moisture_Percent\"],final[\"Dmc\"])).mean() \n",
    "\n",
    "RMSE = round(math.sqrt(MSE),2)\n",
    "print(\"Root Mean Square Error:\\n\")\n",
    "print(RMSE)\n",
    "\n",
    "# using IQR to take out outlayers\n",
    "Q1 = final[\"Difference\"].quantile(0.25)\n",
    "Q3= final[\"Difference\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "final= final[~((final[\"Difference\"] < (Q1 - 1.5 * IQR)) |(final[\"Difference\"] > (Q3 + 1.5 * IQR)))]\n",
    "plt.plot(final[\"Dmc\"],final[\"Moisture_Percent\"],\"o\")\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"Duff MC results comparision at NF, open\")\n",
    "x=np.linspace(0,230)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "MSE = np.square(np.subtract(final[\"Moisture_Percent\"],final[\"Dmc\"])).mean() \n",
    " \n",
    "RMSE = round(math.sqrt(MSE),2)\n",
    "print(\"Root Mean Square Error:\\n\")\n",
    "print(RMSE)\n",
    "\n",
    "\n",
    "#for mature and juv, open:\n",
    "fields2=[\"Location\",\"Stand_Type\",\"Fuel_Type\",\"Date_Collected\",\"Moisture_Percent\"]\n",
    "df2=pd.read_csv(\"2021PgFuel.csv\",skipinitialspace=True,usecols=fields2)\n",
    "location=df2[\"Location\"]==\"NFraser\"\n",
    "fuel=df2[\"Fuel_Type\"]==\"duff\"\n",
    "stand1=df2[\"Stand_Type\"]==\"open\"\n",
    "stand2=df2[\"Stand_Type\"]==\"old\"\n",
    "stand3=df2[\"Stand_Type\"]==\"juvenile\"\n",
    "df_open=df2[location&fuel&stand1]\n",
    "df_old=df2[location&fuel&stand2]\n",
    "df_juv=df2[location&fuel&stand3]\n",
    "#open time matching\n",
    "df_open1=df_open.groupby(pd.to_datetime(df_open[\"Date_Collected\"])).mean()\n",
    "df_open1 = df_open1.reset_index()\n",
    "df_open1[\"Date_Collected\"]=df_open1[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#old time matching\n",
    "df_old1=df_old.groupby(pd.to_datetime(df_old[\"Date_Collected\"])).mean()\n",
    "df_old1 = df_old1.reset_index()\n",
    "df_old1[\"Date_Collected\"]=df_old1[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#juv time matching\n",
    "df_juv1=df_juv.groupby(pd.to_datetime(df_juv[\"Date_Collected\"])).mean()\n",
    "df_juv1 = df_juv1.reset_index()\n",
    "df_juv1[\"Date_Collected\"]=df_juv1[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#time format matching\n",
    "a=pd.to_datetime(df[\"TIMESTAMP\"])\n",
    "a.apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "df[\"TIMESTAMP\"]=a\n",
    "df[\"TIMESTAMP\"]=df[\"TIMESTAMP\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#merging process-final_open\n",
    "finalopen=pd.merge(left=df,right=df_open1,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "finalopen[\"Difference\"]=finalopen[\"Dmc\"]-finalopen[\"Moisture_Percent\"]\n",
    "plt.plot(finalopen[\"Dmc\"],finalopen[\"Moisture_Percent\"],\"o\",label=\"open standing\")\n",
    "\n",
    "\n",
    "MSE1 = np.square(np.subtract(finalopen[\"Moisture_Percent\"],finalopen[\"Dmc\"])).mean() \n",
    " \n",
    "RMSE1= round(math.sqrt(MSE1),2)\n",
    "print(\"Open Root Mean Square Error:\\n\")\n",
    "print(RMSE1)\n",
    "\n",
    "#merging process-final_old\n",
    "finalold=pd.merge(left=df,right=df_old1,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "finalold[\"Difference\"]=finalold[\"Dmc\"]-finalold[\"Moisture_Percent\"]\n",
    "plt.plot(finalold[\"Dmc\"],finalold[\"Moisture_Percent\"],\"o\",label=\"old standing\")\n",
    "\n",
    "\n",
    "MSE2 = np.square(np.subtract(finalold[\"Moisture_Percent\"],finalold[\"Dmc\"])).mean() \n",
    " \n",
    "RMSE2 = round(math.sqrt(MSE2),2)\n",
    "print(\"Old Root Mean Square Error:\\n\")\n",
    "print(RMSE2)\n",
    "\n",
    "#merging process-final_juv\n",
    "\n",
    "finaljuv=pd.merge(left=df,right=df_juv1,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "finaljuv[\"Difference\"]=finaljuv[\"Dmc\"]-finaljuv[\"Moisture_Percent\"]\n",
    "plt.plot(finaljuv[\"Dmc\"],finaljuv[\"Moisture_Percent\"],\"o\",label=\"juv standing\")\n",
    "\n",
    "MSE3 = np.square(np.subtract(finaljuv[\"Moisture_Percent\"],finaljuv[\"Dmc\"])).mean() \n",
    "RMSE3 = round(math.sqrt(MSE3),2)\n",
    "print(\"Juv Root Mean Square Error:\\n\")\n",
    "print(RMSE3)\n",
    "x=np.linspace(0,300)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"Duff MC results comparision at NF\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8dec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# week 5(Feb1-Feb7th)\n",
    "#for mature and juv, open-FFMC, comparing:\n",
    "\n",
    "fields2=[\"Location\",\"Stand_Type\",\"Fuel_Type\",\"Date_Collected\",\"Moisture_Percent\"]\n",
    "df2=pd.read_csv(\"2021PgFuel.csv\",skipinitialspace=True,usecols=fields2)\n",
    "location=df2[\"Location\"]==\"NFraser\"\n",
    "fuel=df2[\"Fuel_Type\"]==\"fines\"\n",
    "stand1=df2[\"Stand_Type\"]==\"open\"\n",
    "stand2=df2[\"Stand_Type\"]==\"old\"\n",
    "stand3=df2[\"Stand_Type\"]==\"juvenile\"\n",
    "df_open=df2[location&fuel&stand1]\n",
    "df_old=df2[location&fuel&stand2]\n",
    "df_juv=df2[location&fuel&stand3]\n",
    "#open time matching\n",
    "df_open1=df_open.groupby(pd.to_datetime(df_open[\"Date_Collected\"])).mean()\n",
    "df_open1 = df_open1.reset_index()\n",
    "df_open1[\"Date_Collected\"]=df_open1[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#old time matching\n",
    "df_old1=df_old.groupby(pd.to_datetime(df_old[\"Date_Collected\"])).mean()\n",
    "df_old1 = df_old1.reset_index()\n",
    "df_old1[\"Date_Collected\"]=df_old1[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#juv time matching\n",
    "df_juv1=df_juv.groupby(pd.to_datetime(df_juv[\"Date_Collected\"])).mean()\n",
    "df_juv1 = df_juv1.reset_index()\n",
    "df_juv1[\"Date_Collected\"]=df_juv1[\"Date_Collected\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#time format matching\n",
    "a=pd.to_datetime(df[\"TIMESTAMP\"])\n",
    "a.apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "df[\"TIMESTAMP\"]=a\n",
    "df[\"TIMESTAMP\"]=df[\"TIMESTAMP\"].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "#merging process-final_open\n",
    "finalopen=pd.merge(left=df,right=df_open1,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "finalopen[\"Difference\"]=finalopen[\"FMC\"]-finalopen[\"Moisture_Percent\"]\n",
    "plt.plot(finalopen[\"FMC\"],finalopen[\"Moisture_Percent\"],\"o\",label=\"open standing\")\n",
    "\n",
    "\n",
    "MSE1 = np.square(np.subtract(finalopen[\"Moisture_Percent\"],finalopen[\"FMC\"])).mean() \n",
    " \n",
    "RMSE1= round(math.sqrt(MSE1),2)\n",
    "print(\"Open Root Mean Square Error:\\n\")\n",
    "print(RMSE1)\n",
    "\n",
    "#merging process-final_old\n",
    "finalold=pd.merge(left=df,right=df_old1,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "finalold[\"Difference\"]=finalold[\"FMC\"]-finalold[\"Moisture_Percent\"]\n",
    "plt.plot(finalold[\"FMC\"],finalold[\"Moisture_Percent\"],\"o\",label=\"old standing\")\n",
    "\n",
    "\n",
    "MSE2 = np.square(np.subtract(finalold[\"Moisture_Percent\"],finalold[\"FMC\"])).mean() \n",
    " \n",
    "RMSE2 = round(math.sqrt(MSE2),2)\n",
    "print(\"Old Root Mean Square Error:\\n\")\n",
    "print(RMSE2)\n",
    "\n",
    "#merging process-final_juv\n",
    "\n",
    "\n",
    "finaljuv=pd.merge(left=df,right=df_juv1,left_on=\"TIMESTAMP\",right_on=\"Date_Collected\")\n",
    "finaljuv[\"Difference\"]=finaljuv[\"FMC\"]-finaljuv[\"Moisture_Percent\"]\n",
    "plt.plot(finaljuv[\"FMC\"],finaljuv[\"Moisture_Percent\"],\"o\",label=\"juv standing\")\n",
    "\n",
    "MSE3 = np.square(np.subtract(finaljuv[\"Moisture_Percent\"],finaljuv[\"FMC\"])).mean() \n",
    "RMSE3 = round(math.sqrt(MSE3),2)\n",
    "print(\"Juv Root Mean Square Error:\\n\")\n",
    "print(RMSE3)\n",
    "x=np.linspace(0,300)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"Fine fuel MC results comparision at NF\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "#IQR process for duff\n",
    "#open\n",
    "Q1_open = finalopen[\"Difference\"].quantile(0.25)\n",
    "Q3_open= finalopen[\"Difference\"].quantile(0.75)\n",
    "IQR_open = Q3_open - Q1_open \n",
    "\n",
    "finalopen1= finalopen[~((finalopen[\"Difference\"] < (Q1_open - 1.5 * IQR_open)) |(finalopen[\"Difference\"] > (Q3_open + 1.5 * IQR_open)))]\n",
    "\n",
    "plt.plot(finalopen1[\"Dmc\"],finalopen1[\"Moisture_Percent\"],\"o\",label=\"open standing\")\n",
    "\n",
    "MSE1 = np.square(np.subtract(finalopen1[\"Moisture_Percent\"],finalopen1[\"Dmc\"])).mean() \n",
    " \n",
    "RMSE1= round(math.sqrt(MSE1),2)\n",
    "print(\"Open Root Mean Square Error:\\n\")\n",
    "print(RMSE1)\n",
    "\n",
    "#old\n",
    "Q1_old = finalold[\"Difference\"].quantile(0.25)\n",
    "Q3_old= finalold[\"Difference\"].quantile(0.75)\n",
    "IQR_old = Q3_old - Q1_old \n",
    "\n",
    "finalold2= finalold[~((finalold[\"Difference\"] < (Q1_old - 1.5 * IQR_old)) |(finalold[\"Difference\"] > (Q3_old + 1.5 * IQR_old)))]\n",
    "\n",
    "plt.plot(finalold2[\"Dmc\"],finalold2[\"Moisture_Percent\"],\"o\",label=\"old standing\")\n",
    "\n",
    "\n",
    "MSE2 = np.square(np.subtract(finalold2[\"Moisture_Percent\"],finalold2[\"Dmc\"])).mean() \n",
    " \n",
    "RMSE2= round(math.sqrt(MSE2),2)\n",
    "print(\"Old Root Mean Square Error:\\n\")\n",
    "print(RMSE2)\n",
    "\n",
    "#juv\n",
    "Q1_juv = finaljuv[\"Difference\"].quantile(0.25)\n",
    "Q3_juv= finaljuv[\"Difference\"].quantile(0.75)\n",
    "IQR_juv = Q3_juv - Q1_juv \n",
    "\n",
    "finaljuv2= finaljuv[~((finaljuv[\"Difference\"] < (Q1_juv - 1.5 * IQR_juv)) |(finaljuv[\"Difference\"] > (Q3_juv + 1.5 * IQR_juv)))]\n",
    "\n",
    "plt.plot(finaljuv2[\"Dmc\"],finaljuv2[\"Moisture_Percent\"],\"o\",label=\"juv standing\")\n",
    "\n",
    "\n",
    "MSE3 = np.square(np.subtract(finaljuv2[\"Moisture_Percent\"],finaljuv2[\"Dmc\"])).mean() \n",
    " \n",
    "RMSE3= round(math.sqrt(MSE3),2)\n",
    "print(\"Old Root Mean Square Error:\\n\")\n",
    "print(RMSE3)\n",
    "x=np.linspace(0,300)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"Duff MC results comparision at NF after IQR\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#IQR process for open\n",
    "#open\n",
    "Q1_open = finalopen[\"Difference\"].quantile(0.25)\n",
    "Q3_open= finalopen[\"Difference\"].quantile(0.75)\n",
    "IQR_open = Q3_open - Q1_open \n",
    "\n",
    "finalopen1= finalopen[~((finalopen[\"Difference\"] < (Q1_open - 1.5 * IQR_open)) |(finalopen[\"Difference\"] > (Q3_open + 1.5 * IQR_open)))]\n",
    "\n",
    "plt.plot(finalopen1[\"FMC\"],finalopen1[\"Moisture_Percent\"],\"o\",label=\"open standing\")\n",
    "\n",
    "MSE1 = np.square(np.subtract(finalopen1[\"Moisture_Percent\"],finalopen1[\"FMC\"])).mean() \n",
    " \n",
    "RMSE1= round(math.sqrt(MSE1),2)\n",
    "print(\"Open Root Mean Square Error:\\n\")\n",
    "print(RMSE1)\n",
    "\n",
    "#old\n",
    "Q1_old = finalold[\"Difference\"].quantile(0.25)\n",
    "Q3_old= finalold[\"Difference\"].quantile(0.75)\n",
    "IQR_old = Q3_old - Q1_old \n",
    "\n",
    "finalold2= finalold[~((finalold[\"Difference\"] < (Q1_old - 1.5 * IQR_old)) |(finalold[\"Difference\"] > (Q3_old + 1.5 * IQR_old)))]\n",
    "\n",
    "plt.plot(finalold2[\"FMC\"],finalold2[\"Moisture_Percent\"],\"o\",label=\"old standing\")\n",
    "\n",
    "\n",
    "MSE2 = np.square(np.subtract(finalold2[\"Moisture_Percent\"],finalold2[\"FMC\"])).mean() \n",
    " \n",
    "RMSE2= round(math.sqrt(MSE2),2)\n",
    "print(\"Old Root Mean Square Error:\\n\")\n",
    "print(RMSE2)\n",
    "\n",
    "#juv\n",
    "Q1_juv = finaljuv[\"Difference\"].quantile(0.25)\n",
    "Q3_juv= finaljuv[\"Difference\"].quantile(0.75)\n",
    "IQR_juv = Q3_juv - Q1_juv \n",
    "\n",
    "finaljuv2= finaljuv[~((finaljuv[\"Difference\"] < (Q1_juv - 1.5 * IQR_juv)) |(finaljuv[\"Difference\"] > (Q3_juv + 1.5 * IQR_juv)))]\n",
    "\n",
    "plt.plot(finaljuv2[\"FMC\"],finaljuv2[\"Moisture_Percent\"],\"o\",label=\"juv standing\")\n",
    "\n",
    "\n",
    "MSE3 = np.square(np.subtract(finaljuv2[\"Moisture_Percent\"],finaljuv2[\"FMC\"])).mean() \n",
    " \n",
    "RMSE3= round(math.sqrt(MSE3),2)\n",
    "print(\"Old Root Mean Square Error:\\n\")\n",
    "print(RMSE3)\n",
    "x=np.linspace(0,300)\n",
    "y=x\n",
    "plt.plot(x,y,'k-')\n",
    "plt.xlabel(\"estimate FMC(%)\")\n",
    "plt.ylabel(\"observation FMC(%)\")\n",
    "plt.title(\"fine fuel MC results comparision at NF after IQR\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# week 5(Feb1-Feb7th)-Remote sensing part, lowess analysis applied for estimate the satelite data:\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import matplotlib.dates as md\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pylab \n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns             \n",
    "from matplotlib.dates import HourLocator, DayLocator, DateFormatter\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "#read files\n",
    "df=pd.read_csv(\"2021PgFuel.csv\")\n",
    "df1=pd.read_csv(\"Bed_30.csv\")\n",
    "#seprate different stand types \n",
    "a1=df['Stand_Type']==\"old\"\n",
    "a2=df['Stand_Type']==\"open\"\n",
    "a3=df['Stand_Type']==\"juvenile\"\n",
    "b1=df[\"Location\"]==\"Bednesti\"\n",
    "c1=df['Fuel_Type']==\"duff\"\n",
    "c2=df[\"Fuel_Type\"]==\"fines\"\n",
    "c3=df[\"Fuel_Type\"]==\"foliage\"\n",
    "#seprate the observation data for foliage\n",
    "#old\n",
    "df2=df[a1&b1&c3]\n",
    "#open\n",
    "df3=df[a2&b1&c3]\n",
    "#juv\n",
    "df4=df[a3&b1&c3]\n",
    "#seprate the ndmi\n",
    "#old\n",
    "d1=df1[\"featureID\"]==\"old\"\n",
    "#open\n",
    "d2=df1[\"featureID\"]==\"open\"\n",
    "#juv\n",
    "d3=df1[\"featureID\"]==\"juv\"\n",
    "\n",
    "#seprate data frame \n",
    "#old-ndmi\n",
    "df5=df1[d1]\n",
    "#open-ndmi\n",
    "df6=df1[d2]\n",
    "#juv-ndmi\n",
    "df7=df1[d3]\n",
    "\n",
    "#lowess analyze for old site \n",
    "#transfer datatime to days for observation data\n",
    "sr=df2[\"Date_Collected\"]\n",
    "sr=pd.to_datetime(sr)\n",
    "result=sr.dt.dayofyear\n",
    "df2[\"days\"]=result\n",
    "#lowess for observation data \n",
    "y_hat1 = lowess(df2[\"Moisture_Percent\"], df2[\"days\"]) # note, default frac=2/3\n",
    "y_hat2 = lowess(df2[\"Moisture_Percent\"], df2[\"days\"], frac=1/5)#more real\n",
    "\n",
    "\n",
    "##transfer datatime to days for ndmi data\n",
    "sr1=df5[\"Date\"]\n",
    "sr1=pd.to_datetime(sr1)\n",
    "result1=sr1.dt.dayofyear\n",
    "df5[\"days\"]=result1\n",
    "##lowess for ndmi data \n",
    "y_hat3 = lowess(df5[\"first\"], df5[\"days\"]) # note, default frac=2/3\n",
    "y_hat4 = lowess(df5[\"first\"], df5[\"days\"], frac=1/5)#more real\n",
    "\n",
    "#to plot for y_hat1 from observation lowess \n",
    "A1=[]\n",
    "for i1 in range(len(y_hat1)):\n",
    "    A1.append(y_hat1[i1][0])\n",
    "B1=[]\n",
    "for j1 in range(len(y_hat1)):\n",
    "    B1.append(y_hat1[j1][1])\n",
    "#extract the values in plot\n",
    "C1=[]\n",
    "C1_e=int(max(A1))\n",
    "C1_s=int(min(A1))\n",
    "C11=[]\n",
    "for t1 in range(C1_s,C1_e):\n",
    "    C1.append(round(np.interp(t1, A1,B1),3))\n",
    "    C11.append(t1)\n",
    "#convert them to df\n",
    "AA1=pd.DataFrame()\n",
    "AA1[\"mc_lowess\"]=C1\n",
    "AA1[\"days_lowess\"]=C11\n",
    "print(AA1)\n",
    "#to plot for y_hat3 from ndmi lowess \n",
    "A3=[]\n",
    "for i3 in range(len(y_hat3)):\n",
    "    A3.append(y_hat3[i3][0])\n",
    "B3=[]\n",
    "for j3 in range(len(y_hat3)):\n",
    "    B3.append(y_hat3[j3][1])\n",
    "#extract the values in plot\n",
    "C3=[]\n",
    "C3_e=int(max(A3))\n",
    "C3_s=int(min(A3))\n",
    "C33=[]\n",
    "for t3 in range(C3_s,C3_e):\n",
    "    C3.append(round(np.interp(t3, A3,B3),3))\n",
    "    C33.append(t3)\n",
    "#convert them to df\n",
    "AA3=pd.DataFrame()\n",
    "AA3[\"ndmi_lowess\"]=C3\n",
    "AA3[\"days_lowess\"]=C33\n",
    "print(AA3)\n",
    "#merge observation and ndmi-lowess-smooth default \n",
    "final_pair1=pd.merge(left=AA1,right=AA3,left_on=\"days_lowess\",right_on=\"days_lowess\")\n",
    "print(final_pair1)\n",
    "plt.plot(final_pair1[\"mc_lowess\"],final_pair1[\"ndmi_lowess\"],\"o\")\n",
    "\n",
    "#to plot for a more real observation data\n",
    "A2=[]\n",
    "for i2 in range(len(y_hat2)):\n",
    "    A2.append(y_hat2[i2][0])\n",
    "B2=[]\n",
    "for j2 in range(len(y_hat2)):\n",
    "    B2.append(y_hat2[j2][1])\n",
    "    \n",
    "#to plot for a more real ndmi data \n",
    "A4=[]\n",
    "for i4 in range(len(y_hat4)):\n",
    "    A4.append(y_hat4[i4][0])\n",
    "B4=[]\n",
    "for j4 in range(len(y_hat4)):\n",
    "    B4.append(y_hat4[j4][1])\n",
    "#extract the values in plot for observation\n",
    "C2=[]\n",
    "C2_e=int(max(A2))\n",
    "C2_s=int(min(A2))\n",
    "C22=[]\n",
    "for t2 in range(C2_s,C2_e):\n",
    "    C2.append(round(np.interp(t2, A2,B2),3))\n",
    "    C22.append(t2)\n",
    "#convert them to df\n",
    "AA2=pd.DataFrame()\n",
    "AA2[\"mc_lowess\"]=C2\n",
    "AA2[\"days_lowess\"]=C22\n",
    "print(AA2)\n",
    "#extract the values in plot for ndmi\n",
    "C4=[]\n",
    "C4_e=int(max(A4))\n",
    "C4_s=int(min(A4))\n",
    "C44=[]\n",
    "for t4 in range(C4_s,C4_e):\n",
    "    C4.append(round(np.interp(t4, A4,B4),3))\n",
    "    C44.append(t4)\n",
    "#convert them to df\n",
    "AA4=pd.DataFrame()\n",
    "AA4[\"ndmi_lowess\"]=C4\n",
    "AA4[\"days_lowess\"]=C44\n",
    "print(AA4)\n",
    "\n",
    "#merge observation and ndmi-lowess-smooth more real \n",
    "final_pair2=pd.merge(left=AA2,right=AA4,left_on=\"days_lowess\",right_on=\"days_lowess\")\n",
    "print(final_pair2)\n",
    "plt.plot(final_pair2[\"mc_lowess\"],final_pair2[\"ndmi_lowess\"],\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd471a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Week 7(java, Feb 15-17), this is writen in java in google earth engine, it has different indices collection model, cloud filter, try it out! \n",
    "//write RS indices functions\n",
    "//NDVI\n",
    "function getNDVI(img) {\n",
    " \n",
    "  var b1 = img.select('B8');\n",
    "  var b2 = img.select('B4');\n",
    " \n",
    "  var image_ndvi = b1.subtract(b2).divide(b1.add(b2)).rename('NDVI');\n",
    " \n",
    "  return img.addBands(image_ndvi)\n",
    "\n",
    "}\n",
    "//NDMI\n",
    "function getNDMI(img) {\n",
    " \n",
    "  var b1 = img.select('B8A');\n",
    "  var b2 = img.select('B11');\n",
    " \n",
    "  var image_ndmi = b1.subtract(b2).divide(b1.add(b2)).rename('NDMI');\n",
    " \n",
    "  return img.addBands(image_ndmi)\n",
    "\n",
    "}\n",
    "\n",
    "//NDWI\n",
    "function getNDWI(img) {\n",
    " \n",
    "  var b1 = img.select('B3');\n",
    "  var b2 = img.select('B8');\n",
    " \n",
    "  var image_ndwi = b1.subtract(b2).divide(b1.add(b2)).rename('NDWI');\n",
    " \n",
    "  return img.addBands(image_ndwi)\n",
    "\n",
    "}\n",
    "\n",
    "//NMDI\n",
    "function getNMDI(img) {\n",
    " \n",
    "  var b1 = img.select('B8A');\n",
    "  var b2 = img.select('B11');\n",
    "  var b3 = img.select('B12');\n",
    " \n",
    "  var image_nmdi = b1.subtract(b2).add(b3).divide(b1.add(b2).subtract(b3)).rename('NMDI');\n",
    " \n",
    "  return img.addBands(image_nmdi)\n",
    "\n",
    "}\n",
    "\n",
    "//VARI\n",
    "function getVARI(img) {\n",
    " \n",
    "  var b1 = img.select('B3');\n",
    "  var b2 = img.select('B4');\n",
    "  var b3= img.select('B2');\n",
    " \n",
    "  var image_vari = b1.subtract(b2).divide(b1.subtract(b2).subtract(b3)).rename('VARI');\n",
    " \n",
    "  return img.addBands(image_vari)\n",
    "}\n",
    "var getQABits = function(image, start, end, newName) {\n",
    "    // Compute the bits we need to extract.\n",
    "    var pattern = 0;\n",
    "    for (var i = start; i <= end; i++) {\n",
    "       pattern += Math.pow(2, i);\n",
    "    }\n",
    "    // Return a single band image of the extracted QA bits, giving the band\n",
    "    // a new name.\n",
    "    return image.select([0], [newName])\n",
    "                  .bitwiseAnd(pattern)\n",
    "                  .rightShift(start);\n",
    "};\n",
    "\n",
    "var getshadowbits=function(image,newName){\n",
    "  return image.select([0],[newName])\n",
    "}\n",
    "// A function to mask out cloudy pixels.\n",
    "var clouds = function(image) {\n",
    "  // Select the QA band.\n",
    "  var QA = image.select(['QA60']);\n",
    "  // Get the internal_cloud_algorithm_flag bit.\n",
    "  return getQABits(QA, 10,10, 'cloud');\n",
    "  // Return an image masking out cloudy areas.\n",
    "};\n",
    "\n",
    "//a function to mask out cirrus clody pixels \n",
    "var cloud_cirrus = function(image) {\n",
    "  // Select the QA band.\n",
    "  var QA = image.select(['QA60']);\n",
    "  // Get the internal_cloud_algorithm_flag bit.\n",
    "  return getQABits(QA, 11,11, 'cloud_cirrus');\n",
    "  // Return an image masking out cloudy areas.\n",
    "};\n",
    "// Define a different standing object at Bednesti,SC,NF,HS,CP,MCD\n",
    "\n",
    "\n",
    "\n",
    "var open= [\n",
    "  ee.Feature(ee.Geometry.Point(-123.37044,53.871334), {name: 'BED',stand:\"open\"}).buffer({'distance': 35\n",
    "}),\n",
    "  ee.Feature(ee.Geometry.Point(-122.53790840362969,53.61666478088408), {name: 'SC',stand:\"open\"}).buffer({'distance': 35\n",
    "}),\n",
    "  ee.Feature(ee.Geometry.Point(-122.4906471114409,54.24422366683115), {name: 'NF',stand:\"open\"}).buffer({'distance': 35\n",
    "}),\n",
    "  ee.Feature(ee.Geometry.Point(-126.61521957203071,54.510560458595215), {name: 'HS',stand:\"open\"}).buffer({'distance': 35\n",
    "}),\n",
    "  ee.Feature(ee.Geometry.Point(-126.62338922091105,54.88414223445725), {name: 'CP',stand:\"open\"}).buffer({'distance': 35\n",
    "}),\n",
    "  ee.Feature(ee.Geometry.Point(-127.51496699805071,54.78263617031289), {name: 'MCD',stand:\"open\"}).buffer({'distance': 35\n",
    "}),\n",
    "];\n",
    "\n",
    "\n",
    "\n",
    "//assign locations and points \n",
    "//JUV\n",
    "var juvbed=ee.Geometry.Point(-123.37023,53.8701).buffer({'distance': 35\n",
    "});\n",
    "var juvsc=ee.Geometry.Point(-122.53568,53.6161).buffer({'distance': 35\n",
    "});\n",
    "var juvnf=ee.Geometry.Point(-122.48724,54.2440).buffer({'distance': 35\n",
    "});\n",
    "var juvhs=ee.Geometry.Point(-126.6145329265229,54.50762042679731).buffer({'distance': 35\n",
    "});\n",
    "var juvcp=ee.Geometry.Point(-126.6371221310673,54.88303133721306).buffer({'distance': 35\n",
    "});\n",
    "var juvmcd=ee.Geometry.Point(-127.52016195737143,54.78083388146724).buffer({'distance': 35\n",
    "})\n",
    "var juv_bed = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: juvbed,\n",
    "  scale: 30\n",
    "});\n",
    "var juv_sc = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: juvsc,\n",
    "  scale: 30\n",
    "});\n",
    "var juv_nf = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: juvnf,\n",
    "  scale: 30\n",
    "});\n",
    "var juv_hs = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: juvhs,\n",
    "  scale: 30\n",
    "});\n",
    "var juv_cp = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: juvcp,\n",
    "  scale: 30\n",
    "});\n",
    "var juv_mcd = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: juvmcd,\n",
    "  scale: 30\n",
    "});\n",
    "\n",
    "//Make gridded points per each lat and long for juv\n",
    "var juv_bed = ee.FeatureCollection(juv_bed.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"juv\",\n",
    "        'loc':'BED'\n",
    "      });\n",
    "    });\n",
    "var juv_sc = ee.FeatureCollection(juv_sc.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"juv\",\n",
    "        'loc':'SC'\n",
    "      });\n",
    "    });\n",
    "var juv_nf = ee.FeatureCollection(juv_nf.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"juv\",\n",
    "        'loc':'NF'\n",
    "      });\n",
    "    });\n",
    "var juv_hs = ee.FeatureCollection(juv_hs.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"juv\",\n",
    "        'loc':'HS'\n",
    "      });\n",
    "    });\n",
    "    \n",
    "var juv_cp = ee.FeatureCollection(juv_mcd.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"juv\",\n",
    "        'loc':'CP'\n",
    "      });\n",
    "    });\n",
    "    \n",
    "var juv_mcd = ee.FeatureCollection(juv_mcd.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"juv\",\n",
    "        'loc':'MCD'\n",
    "      });\n",
    "    });\n",
    "var juv_points=juv_bed.merge(juv_sc).merge(juv_nf).merge(juv_hs).merge(juv_cp).merge(juv_mcd);\n",
    "\n",
    "//old\n",
    "var oldbed=ee.Geometry.Point(-123.36881, 53.872643).buffer({'distance': 35\n",
    "});\n",
    "var oldsc=  ee.Geometry.Point(-122.53694697444689,53.614360884145256).buffer({'distance': 35\n",
    "});\n",
    "var oldnf=  ee.Geometry.Point(-122.48998222029618,54.24231946275022).buffer({'distance': 35\n",
    "});\n",
    "var oldhs=  ee.Geometry.Point(-126.61225841327827,54.512005481417084).buffer({'distance': 35\n",
    "});\n",
    "var oldcp= ee.Geometry.Point(-126.64212176867106,54.88426566559375).buffer({'distance': 35\n",
    "});\n",
    "var oldmcd=ee.Geometry.Point(-127.5061049794655,54.78168334500671).buffer({'distance': 35\n",
    "});\n",
    "\n",
    "\n",
    "var old_bed = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: oldbed,\n",
    "  scale: 30\n",
    "});\n",
    "var old_sc = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: oldsc,\n",
    "  scale: 30\n",
    "});\n",
    "var old_nf = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: oldnf,\n",
    "  scale: 30\n",
    "});\n",
    "var old_hs = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: oldhs,\n",
    "  scale: 30\n",
    "});\n",
    "var old_cp = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: oldcp,\n",
    "  scale: 30\n",
    "});\n",
    "var old_mcd = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: oldmcd,\n",
    "  scale: 30\n",
    "});\n",
    "\n",
    "//Make gridded points per each lat and long for juv\n",
    "var old_bed = ee.FeatureCollection(old_bed.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"old\",\n",
    "        'loc':'BED'\n",
    "      });\n",
    "    });\n",
    "var old_sc = ee.FeatureCollection(old_sc.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"old\",\n",
    "        'loc':'SC'\n",
    "      });\n",
    "    });\n",
    "var old_nf = ee.FeatureCollection(old_nf.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"old\",\n",
    "        'loc':'NF'\n",
    "      });\n",
    "    });\n",
    "var old_hs = ee.FeatureCollection(old_hs.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"old\",\n",
    "        'loc':'HS'\n",
    "      });\n",
    "    });\n",
    "    \n",
    "var old_cp = ee.FeatureCollection(old_mcd.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"old\",\n",
    "        'loc':'CP'\n",
    "      });\n",
    "    });\n",
    "    \n",
    "var old_mcd = ee.FeatureCollection(old_mcd.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"old\",\n",
    "        'loc':'MCD'\n",
    "      });\n",
    "    });\n",
    "    \n",
    "var old_points=old_bed.merge(old_sc).merge(old_nf).merge(old_hs).merge(old_cp).merge(old_mcd);    \n",
    "var openbed= \n",
    "  ee.Geometry.Point(-123.37044,53.871334).buffer({'distance': 35\n",
    "});\n",
    "var opensc= ee.Geometry.Point(-122.53790840362969,53.61666478088408).buffer({'distance': 35\n",
    "});\n",
    "var opennf=ee.Geometry.Point(-122.4906471114409,54.24422366683115).buffer({'distance': 35\n",
    "});\n",
    "var openhs=ee.Geometry.Point(-126.61521957203071,54.510560458595215).buffer({'distance': 35\n",
    "});\n",
    "var opencp= ee.Geometry.Point(-126.62338922091105,54.88414223445725).buffer({'distance': 35\n",
    "});\n",
    "var openmcd= ee.Geometry.Point(-127.51496699805071,54.78263617031289).buffer({'distance': 35\n",
    "});\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "var open_bed = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: openbed,\n",
    "  scale: 30\n",
    "});\n",
    "var open_sc = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: opensc,\n",
    "  scale: 30\n",
    "});\n",
    "var open_nf = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: opennf,\n",
    "  scale: 30\n",
    "});\n",
    "var open_hs = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: openhs,\n",
    "  scale: 30\n",
    "});\n",
    "var open_cp = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: opencp,\n",
    "  scale: 30\n",
    "});\n",
    "var open_mcd = ee.Image.pixelLonLat().reduceRegion({\n",
    "  reducer: ee.Reducer.toCollection(['longitude', 'latitude']), \n",
    "  geometry: openmcd,\n",
    "  scale: 30\n",
    "});\n",
    "\n",
    "//Make gridded points per each lat and long for juv\n",
    "var open_bed = ee.FeatureCollection(open_bed.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"open\",\n",
    "        'loc':'BED'\n",
    "      });\n",
    "    });\n",
    "var open_sc = ee.FeatureCollection(open_sc.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"open\",\n",
    "        'loc':'SC'\n",
    "      });\n",
    "    });\n",
    "var open_nf = ee.FeatureCollection(open_nf.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"open\",\n",
    "        'loc':'NF'\n",
    "      });\n",
    "    });\n",
    "var open_hs = ee.FeatureCollection(open_hs.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"open\",\n",
    "        'loc':'HS'\n",
    "      });\n",
    "    });\n",
    "    \n",
    "var open_cp = ee.FeatureCollection(open_mcd.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"open\",\n",
    "        'loc':'CP'\n",
    "      });\n",
    "    });\n",
    "    \n",
    "var open_mcd = ee.FeatureCollection(open_mcd.get('features'))\n",
    "    .map(function(feature) {\n",
    "      var lon = feature.get('longitude');\n",
    "      var lat = feature.get('latitude');\n",
    "      return ee.Feature(ee.Geometry.Point([lon, lat]), {\n",
    "        'featureID': \"open\",\n",
    "        'loc':'MCD'\n",
    "      });\n",
    "    });\n",
    "\n",
    "var open_points=open_bed.merge(open_sc).merge(open_nf).merge(open_hs).merge(open_cp).merge(open_mcd);\n",
    "    \n",
    "var out_points = juv_points.merge(old_points).merge(open_points)\n",
    "print(out_points, 'Final Sample Points')\n",
    "Map.addLayer(out_points, null, 'Sample_Points');\n",
    "\n",
    "var geo=[ee.Feature(geometry,{name: 'BED'}),\n",
    "ee.Feature(geometry2,{name: 'SC'}),\n",
    "ee.Feature(geometry3,{name: 'NF'}),\n",
    "ee.Feature(geometry4,{name: 'HS'}),\n",
    "ee.Feature(geometry5,{name: 'CP'}),\n",
    "ee.Feature(geometry6,{name: 'MCD'})]\n",
    "\n",
    "var geo = ee.FeatureCollection(geo)\n",
    "\n",
    "//data\n",
    "var S2 =ee.ImageCollection('COPERNICUS/S2')\n",
    "          .filterDate('2021-06-01', '2021-09-30');\n",
    "\n",
    "var c = S2.filterBounds(geo);\n",
    "var c1 = c.map(function(image){return ee.Image(image).clip(geo)})\n",
    "\n",
    "//first filter \n",
    "var withCloudiness = c1.map(function(image) {\n",
    "  var cloud = clouds(image);\n",
    "  var cloudiness = cloud.reduceRegion({\n",
    "    reducer: 'mean', \n",
    "    geometry: geo, \n",
    "    scale: 30,\n",
    "    crs:'EPSG:3857'\n",
    "  });\n",
    "  return image.set(cloudiness);\n",
    "});\n",
    "\n",
    "var withCloudiness1 = withCloudiness.map(function(image) {\n",
    "  var cloud1 = cloud_cirrus(image);\n",
    "  var cloudiness1 = cloud1.reduceRegion({\n",
    "    reducer: 'mean', \n",
    "    geometry: geo, \n",
    "    scale: 30,\n",
    "    crs:'EPSG:3857'\n",
    "  });\n",
    "  return image.set(cloudiness1);\n",
    "});\n",
    "\n",
    "\n",
    "\n",
    "var filteredCollection = withCloudiness1\n",
    "            .filter(ee.Filter.and(\n",
    "            ee.Filter.lt('cloud', 0.01),\n",
    "            ee.Filter.lt('cloud_cirrus', 0.01)))\n",
    "            .map(getNDVI);\n",
    "var filteredCollection=filteredCollection.map(getNDMI);  \n",
    "var filteredCollection=filteredCollection.map(getNDWI);\n",
    "var filteredCollection=filteredCollection.map(getNMDI);\n",
    "var filteredCollection=filteredCollection.map(getVARI);\n",
    "print(filteredCollection)\n",
    "\n",
    "//extract image values at points\n",
    "//NDVI\n",
    "var points_NDVI = filteredCollection.select('NDVI').map(function(image) {\n",
    "  return image.reduceRegions({\n",
    "    collection: out_points, \n",
    "    reducer: ee.Reducer.first(), //this is how the points are calculated \n",
    "    scale: 30,\n",
    "  }).map(function(feature) {\n",
    "    return feature.set({\n",
    "      'imageID': image.id(),\n",
    "      'Date':  ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
    "      'indices': \"NDVI\"\n",
    "    })\n",
    "  });\n",
    "}).flatten();\n",
    "\n",
    "//gt rid of nulls\n",
    "points_NDVI = points_NDVI.filter(ee.Filter.notNull(['first']))\n",
    "print(points_NDVI)\n",
    "//NDMI\n",
    "var points_NDMI = filteredCollection.select('NDMI').map(function(image) {\n",
    "  return image.reduceRegions({\n",
    "    collection: out_points, \n",
    "    reducer: ee.Reducer.first(), //this is how the points are calculated \n",
    "    scale: 30,\n",
    "  }).map(function(feature) {\n",
    "    return feature.set({\n",
    "      'imageID': image.id(),\n",
    "      'Date':  ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
    "      'indices': \"NDMI\"\n",
    "    })\n",
    "  });\n",
    "}).flatten();\n",
    "\n",
    "//gt rid of nulls\n",
    "points_NDMI = points_NDMI.filter(ee.Filter.notNull(['first']))\n",
    "\n",
    "//NDWI\n",
    "var points_NDWI = filteredCollection.select('NDWI').map(function(image) {\n",
    "  return image.reduceRegions({\n",
    "    collection: out_points, \n",
    "    reducer: ee.Reducer.first(), //this is how the points are calculated \n",
    "    scale: 30,\n",
    "  }).map(function(feature) {\n",
    "    return feature.set({\n",
    "      'imageID': image.id(),\n",
    "      'Date':  ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
    "      'indices': \"NDWI\"\n",
    "    })\n",
    "  });\n",
    "}).flatten();\n",
    "\n",
    "//gt rid of nulls\n",
    "points_NDWI = points_NDWI.filter(ee.Filter.notNull(['first']))\n",
    "\n",
    "//NMDI\n",
    "var points_NMDI = filteredCollection.select('NMDI').map(function(image) {\n",
    "  return image.reduceRegions({\n",
    "    collection: out_points, \n",
    "    reducer: ee.Reducer.first(), //this is how the points are calculated \n",
    "    scale: 30,\n",
    "  }).map(function(feature) {\n",
    "    return feature.set({\n",
    "      'imageID': image.id(),\n",
    "      'Date':  ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
    "      'indices': \"NMDI\"\n",
    "    })\n",
    "  });\n",
    "}).flatten();\n",
    "\n",
    "//gt rid of nulls\n",
    "points_NMDI = points_NMDI.filter(ee.Filter.notNull(['first']))\n",
    "\n",
    "\n",
    "//VARI\n",
    "var points_VARI = filteredCollection.select('VARI').map(function(image) {\n",
    "  return image.reduceRegions({\n",
    "    collection: out_points, \n",
    "    reducer: ee.Reducer.first(), //this is how the points are calculated \n",
    "    scale: 30,\n",
    "  }).map(function(feature) {\n",
    "    return feature.set({\n",
    "      'imageID': image.id(),\n",
    "      'Date':  ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
    "      'indices': \"VARI\"\n",
    "    })\n",
    "  });\n",
    "}).flatten();\n",
    "\n",
    "//gt rid of nulls\n",
    "points_VARI = points_VARI.filter(ee.Filter.notNull(['first']))\n",
    "//check\n",
    "\n",
    "//merge together \n",
    "var upper_a=points_NDVI.merge(points_NDMI).merge(points_NDWI).merge(points_NMDI).merge(points_VARI)\n",
    "\n",
    "print(upper_a)\n",
    "//export to drive\n",
    "Export.table.toDrive({\n",
    "  collection: upper_a, \n",
    "  description:\"bednesti\"+ 2021, \n",
    "  fileNamePrefix: 'Diff_stand_NDMI'+ 2021, \n",
    "  fileFormat: 'CSV',\n",
    "  folder: 'GEOG650'\n",
    "}); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week 8 Feb 28th-March5th\n",
    "#min-max test, some statistic work \n",
    "#bed\n",
    "dfbed=[]\n",
    "dfbed=pd.DataFrame(dfbed)\n",
    "dfbed=dfbed.append(Bed_R,ignore_index=True).append(Bed_R1, ignore_index=True)\n",
    "dfbed[\"nor\"] = \"\"\n",
    "a=max(dfbed[\"ndmi_lowess\"])\n",
    "b=min(dfbed[\"ndmi_lowess\"])\n",
    "c=dfbed[\"ndmi_lowess\"]\n",
    "for i in range(len(c)):\n",
    "    dfbed[\"nor\"][i]=(c[i]-b)/(a-b)\n",
    "\n",
    "    \n",
    "#NF    \n",
    "dfnf=[]\n",
    "dfnf=pd.DataFrame(dfnf)\n",
    "dfnf=dfnf.append(NF_R,ignore_index=True).append(NF_R1, ignore_index=True)\n",
    "dfnf[\"nor\"] = \"\"\n",
    "a=max(dfnf[\"ndmi_lowess\"])\n",
    "b=min(dfnf[\"ndmi_lowess\"])\n",
    "c=dfnf[\"ndmi_lowess\"]\n",
    "for i in range(len(c)):\n",
    "    dfnf[\"nor\"][i]=(c[i]-b)/(a-b)\n",
    "    \n",
    "#sc\n",
    "dfsc=[]\n",
    "dfsc=pd.DataFrame(dfsc)\n",
    "dfsc=dfsc.append(SC_R,ignore_index=True).append(SC_R1, ignore_index=True)\n",
    "dfsc[\"nor\"] = \"\"\n",
    "a=max(dfsc[\"ndmi_lowess\"])\n",
    "b=min(dfsc[\"ndmi_lowess\"])\n",
    "c=dfsc[\"ndmi_lowess\"]\n",
    "for i in range(len(c)):\n",
    "    dfsc[\"nor\"][i]=(c[i]-b)/(a-b)\n",
    "\n",
    "#HS   \n",
    "dfhs=[]\n",
    "dfhs=pd.DataFrame(dfbed)\n",
    "dfhs=dfhs.append(HS_R,ignore_index=True).append(HS_R1, ignore_index=True)\n",
    "dfhs[\"nor\"] = \"\"\n",
    "a=max(dfhs[\"ndmi_lowess\"])\n",
    "b=min(dfhs[\"ndmi_lowess\"])\n",
    "c=dfhs[\"ndmi_lowess\"]\n",
    "for i in range(len(c)):\n",
    "    dfhs[\"nor\"][i]=(c[i]-b)/(a-b)\n",
    "\n",
    "\n",
    "#CP\n",
    "dfcp=[]\n",
    "dfcp=pd.DataFrame(dfcp)\n",
    "dfcp=dfcp.append(CP_R,ignore_index=True).append(CP_R1, ignore_index=True)\n",
    "dfcp[\"nor\"] = \"\"\n",
    "a=max(dfcp[\"ndmi_lowess\"])\n",
    "b=min(dfcp[\"ndmi_lowess\"])\n",
    "c=dfcp[\"ndmi_lowess\"]\n",
    "for i in range(len(c)):\n",
    "    dfcp[\"nor\"][i]=(c[i]-b)/(a-b)\n",
    "    \n",
    "#MCD\n",
    "dfmcd=[]\n",
    "dfmcd=pd.DataFrame(dfmcd)\n",
    "dfmcd=dfmcd.append(MCD_R,ignore_index=True).append(MCD_R1, ignore_index=True)\n",
    "dfmcd[\"nor\"] = \"\"\n",
    "a=max(dfmcd[\"ndmi_lowess\"])\n",
    "b=min(dfmcd[\"ndmi_lowess\"])\n",
    "c=dfmcd[\"ndmi_lowess\"]\n",
    "for i in range(len(c)):\n",
    "    dfmcd[\"nor\"][i]=(c[i]-b)/(a-b)\n",
    "    \n",
    "\n",
    "dfNDMI=[]\n",
    "dfNDMI=pd.DataFrame(dfNDMI)\n",
    "dfNDMI=dfNDMI.append(dfbed, ignore_index=True).append(dfnf, ignore_index=True).append(dfsc, ignore_index=True).append(dfhs, ignore_index=True).append(dfcp, ignore_index=True).append(dfmcd, ignore_index=True)\n",
    "\n",
    "import scipy.stats\n",
    "plt.plot(dfNDMI[\"nor\"],dfNDMI[\"Moisture_Percent\"],\"o\")\n",
    "plt.xlabel('nor') \n",
    "plt.ylabel('MC') \n",
    "  \n",
    "\n",
    "plt.title(\"juv MC vs Normalized NDMI\")\n",
    "m, b = np.polyfit(dfNDMI[\"nor\"].astype(str).astype(float),dfNDMI[\"Moisture_Percent\"], 1)\n",
    "print(\"mc=\",round(m,2),\"nor+\",round(b,2))\n",
    "\n",
    "plt.plot(dfNDMI[\"nor\"], m*dfNDMI[\"nor\"] + b)\n",
    "\n",
    "import math\n",
    "#RMSE\n",
    "Rr=[]\n",
    "Rp=[]\n",
    "for i in range(len(dfNDMI)):\n",
    "    Rr.append(dfNDMI[\"Moisture_Percent\"][i])\n",
    "for j in range(len(dfNDMI)):\n",
    "    Rp.append(26.53*dfNDMI[\"nor\"]+100.27)\n",
    "MSE = np.square(np.subtract(Rr,Rp)).mean() \n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"Root Mean Square Error:\\n\")\n",
    "print(RMSE) \n",
    "print(\"correlation value for NDMI\", format(scipy.stats.pearsonr(dfNDMI[\"nor\"], dfNDMI[\"Moisture_Percent\"])[0],\"2f\"))\n",
    "print(\"P value for NDMI\", format(scipy.stats.pearsonr(dfNDMI[\"nor\"], dfNDMI[\"Moisture_Percent\"])[1],\"2f\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45408d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week 9 March 6th to March 13th, functions build up, shorten my coding for remote sensing work, a lot of IQR filter fuctions and linear regression function. feel free to borrow:\n",
    "\n",
    "#functions\n",
    "def iqr_observ(df):\n",
    "    df[\"days\"]=pd.to_datetime(df[\"Date_Collected\"]).dt.dayofyear\n",
    "    a=df.groupby(\"days\")['Moisture_Percent'].apply(list).reset_index(name='new')\n",
    "    a.index.name = None\n",
    "    b=[]\n",
    "    c=[]\n",
    "    for i in range(len(a)):\n",
    "        q1 = np.quantile(a[\"new\"][i],0.25)\n",
    "        q3 = np.quantile(a[\"new\"][i],0.75)\n",
    "        iqr = q3-q1 #Interquartile range\n",
    "        fence_low  = q1-1.5*iqr\n",
    "        fence_high = q3+1.5*iqr\n",
    "        for j in range(len(a[\"new\"][i])):\n",
    "            if (a[\"new\"][i][j] > fence_low) & (a[\"new\"][i][j] < fence_high):\n",
    "                b.append(a[\"new\"][i][j])\n",
    "                c.append(a[\"days\"][i])\n",
    "    d = {'days':c,'Moisture_Percent':b}\n",
    "    df = pd.DataFrame(d) \n",
    "    return df\n",
    "\n",
    "def iqr_indices(df):\n",
    "    a=df.groupby(\"Date\")['first'].apply(list).reset_index(name='new')\n",
    "    a.index.name = None\n",
    "    b=[]\n",
    "    c=[]\n",
    "    for i in range(len(a)):\n",
    "        q1 = np.quantile(a[\"new\"][i],0.25)\n",
    "        q3 = np.quantile(a[\"new\"][i],0.75)\n",
    "        iqr = q3-q1 #Interquartile range\n",
    "        fence_low  = q1-1.5*iqr\n",
    "        fence_high = q3+1.5*iqr\n",
    "        for j in range(len(a[\"new\"][i])):\n",
    "            if (a[\"new\"][i][j] > fence_low) & (a[\"new\"][i][j] < fence_high):\n",
    "                b.append(a[\"new\"][i][j])\n",
    "                c.append(a[\"Date\"][i])\n",
    "    d = {'Date':c,'first':b}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "#a is start date, b is end date c is fraction for lowess \n",
    "def Lowess(df, a, b, c):\n",
    "    df[\"days\"]=pd.to_datetime(df[\"Date\"]).dt.dayofyear\n",
    "    df= df[(df['days'] > a) & (df['days'] <= b)]\n",
    "\n",
    "    y_hat3 = lowess(df[\"first\"],df[\"days\"],frac=c) \n",
    "    #merge process \n",
    "    A3=[]\n",
    "    for i3 in range(len(y_hat3)):\n",
    "        A3.append(y_hat3[i3][0])\n",
    "    B3=[]\n",
    "    for j3 in range(len(y_hat3)):\n",
    "        B3.append(y_hat3[j3][1])\n",
    "    #extract the values in plot\n",
    "    \n",
    "    C3=[]\n",
    "    C3_e=int(max(A3))\n",
    "    C3_s=int(min(A3))\n",
    "    C33=[]\n",
    "    for t3 in range(C3_s,C3_e):\n",
    "        C3.append(round(np.interp(t3, A3,B3),3))\n",
    "        C33.append(t3)\n",
    "    #convert them to df\n",
    "\n",
    "    Bed_NDMI_lowess_D1=pd.DataFrame()\n",
    "    Bed_NDMI_lowess_D1[\"ndmi_lowess\"]=C3\n",
    "    Bed_NDMI_lowess_D1[\"days_lowess\"]=C33\n",
    "    return Bed_NDMI_lowess_D1\n",
    "\n",
    "#df1 is the \n",
    "def merge(df1,df2):\n",
    "    df1[\"ndmi_lowess\"]=\"\"\n",
    "    for i in range(len(df1)):\n",
    "        for j in range(len(df2)):\n",
    "            if df1[\"days\"][i] == df2[\"days_lowess\"][j]:\n",
    "                df1[\"ndmi_lowess\"][i]=df2[\"ndmi_lowess\"][j]\n",
    "    return  df1\n",
    "#data solution\n",
    "def fix(df):\n",
    "    nan_value = float(\"NaN\")\n",
    "    df.replace(\"\", nan_value, inplace=True)\n",
    "    df.dropna(subset = [\"ndmi_lowess\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "#a is k, b is b\n",
    "def iqr_final(df,a,b):\n",
    "    \n",
    "    Rr=[]\n",
    "    Rp=[]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        Rr.append(df[\"Moisture_Percent\"][i])\n",
    "    for j in range(len(df)):\n",
    "        Rp.append(a*df[\"ndmi_lowess\"][j]+b)\n",
    "    df[\"Rr\"]=Rr\n",
    "    df[\"Rp\"]=Rp\n",
    "    FF=df[\"Rr\"]-df[\"Rp\"]\n",
    "    df[\"FF\"]=abs(FF)\n",
    "    Q1 = df[\"FF\"].quantile(0.25)\n",
    "    Q3 = df[\"FF\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df=df.query('(@Q1 - 1.5 * @IQR) <= FF<= (@Q3 + 1.5 * @IQR)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 10 March 14th-Marth 21st: linear regression from last week applied in post fire area, this is an example .\n",
    "fig,ax=plt.subplots(2, figsize=(10,6),sharex=True)\n",
    "L1=ax[0].plot(pd.to_datetime(juvVARI[\"Date\"]),juvVARI[\"first\"]*(142.96)+191.74,\"o\",color=\"b\",label=\"juv-VARI\")\n",
    "L2=ax[0].plot(pd.to_datetime(matVARI[\"Date\"]),matVARI[\"first\"]*136.32+188.85,\"o\",color=\"r\",label=\"mat-VARi\")\n",
    "L=L1+L2\n",
    "labs=[l.get_label()for l in L]\n",
    "ax[0].legend(L,labs,loc=2)\n",
    "L11=ax[1].plot(pd.to_datetime(juvNDVI[\"Date\"]),juvNDVI[\"first\"]*(-124.74)+201.31,\"o\",color=\"b\",label=\"juv-NDVI\")\n",
    "L22=ax[1].plot(pd.to_datetime(matNDVI[\"Date\"]),matNDVI[\"first\"]*(-268.35)+300.09,\"o\",color=\"r\",label=\"mat-NDVI\")\n",
    "LL=L11+L22\n",
    "labs1=[l.get_label()for l in LL]\n",
    "ax[1].legend(LL,labs1,loc=2)\n",
    "ax[0].set_ylabel(\"Moisture Percent\")\n",
    "ax[1].set_xlabel(\"Date\")\n",
    "ax[1].set_ylabel(\"Moisture Percent\")\n",
    "fig.suptitle(\"juv vs mat post fire MC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 11 Marth 22nd to Marth 29th: some java work in GEE(google earth engine), burn severity functions and coding!\n",
    "//===========================================================================================\n",
    "//             BURN SEVERITY MAPPING USING THE NORMALIZED BURN RATIO (NBR)\n",
    "//===========================================================================================\n",
    "// Normalized Burn Ratio will be applied to imagery from before and after a wild fire. By\n",
    "// calculating the difference afterwards (dNBR) Burn Severity is derived, showing the spatial\n",
    "// impact of the disturbance. Imagery used in this process comes from either Sentinel-2 or \n",
    "// Landsat 8.\n",
    "//===========================================================================================\n",
    "\n",
    "//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "//                                    RUN A DEMO (optional)\n",
    "\n",
    "// If you would like to run an example of mapping burn severity you can use the predefined \n",
    "// geometry below as well as the other predefined parameter settings. The code will take you\n",
    "// to Empredado, Chile where wildfires devasted large forested areas in January and February \n",
    "// of 2017. \n",
    "// --> Remove the comment-symbol (//) below to so Earth Engine recognizes the polygon.\n",
    "\n",
    "// Now hit Run to start the demo! \n",
    "// Do not forget to delete/outcomment this geometry before creating a new one!\n",
    "//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "//*******************************************************************************************\n",
    "//                             SELECT YOUR OWN STUDY AREA   \n",
    "\n",
    "// Use the polygon-tool in the top left corner of the map pane to draw the shape of your \n",
    "// study area. Single clicks add vertices, double-clicking completes the polygon.\n",
    "// **CAREFUL**: Under 'Geometry Imports' (top left in map pane) uncheck the \n",
    "//                geometry box, so it does not block the view on the imagery later.\n",
    "\n",
    "//*******************************************************************************************\n",
    "//                                     SET TIME FRAME\n",
    "\n",
    "// Set start and end dates of a period BEFORE the fire. Make sure it is long enough for \n",
    "// Sentinel-2 to acquire an image (repitition rate = 5 days). Adjust these parameters, if\n",
    "// your ImageCollections (see Console) do not contain any elements.\n",
    "var prefire_start = '2017-04-07';   \n",
    "var prefire_end = '2017-07-07';\n",
    "\n",
    "// Now set the same parameters for AFTER the fire.\n",
    "var postfire_start = '2017-09-01';\n",
    "var postfire_end = '2018-07-31';\n",
    "\n",
    "//*******************************************************************************************\n",
    "//                            SELECT A SATELLITE PLATFORM\n",
    "\n",
    "// You can select remote sensing imagery from two availible satellite sensors. \n",
    "// Consider details of each mission below to choose the data suitable for your needs.\n",
    "\n",
    "// Landsat 8                             |  Sentinel-2 (A&B)\n",
    "//-------------------------------------------------------------------------------------------\n",
    "// launched:        February 11th, 2015  |  June 23rd, 2015 & March 7th, 2017\n",
    "// repitition rate: 16 days              |  5 day (since 2017)\n",
    "// resolution:      30 meters            |  10 meters \n",
    "// advantages:      longer time series   |  9 times higher spatial detail\n",
    "//                  smaller export file  |  higher chance of cloud-free images\n",
    "\n",
    "// SELECT one of the following:   'L8'  or 'S2' \n",
    "\n",
    "var platform = 'L8';               // <--- assign your choice to the platform variable\n",
    "\n",
    "//*******************************************************************************************\n",
    "//---->>> DO NOT EDIT THE SCRIPT PAST THIS POINT! (unless you know what you are doing) <<<---\n",
    "//------------------->>> NOW HIT 'RUN' AT THE TOP OF THE SCRIPT! <<<-------------------------\n",
    "//--> THE FINAL BURN SEVERITY PRODUCT WILL READY FOR DOWNLOAD ON THE RIGHT (UNDER TASKS) <---\n",
    "\n",
    "//*******************************************************************************************\n",
    "\n",
    "\n",
    "//---------------------------------- Translating User Inputs --------------------------------\n",
    "\n",
    "// Print Satellite platform and dates to console\n",
    "if (platform == 'S2' | platform == 's2') {\n",
    "  var ImCol = 'COPERNICUS/S2';\n",
    "  var pl = 'Sentinel-2';\n",
    "} else {\n",
    "  var ImCol = 'LANDSAT/LC08/C01/T1_SR';\n",
    "  var pl = 'Landsat 8';\n",
    "}\n",
    "print(ee.String('Data selected for analysis: ').cat(pl));\n",
    "print(ee.String('Fire incident occurred between ').cat(prefire_end).cat(' and ').cat(postfire_start));\n",
    "\n",
    "// Location\n",
    "var area = ee.FeatureCollection(geometry);\n",
    "\n",
    "// Set study area as map center.\n",
    "Map.centerObject(area);\n",
    "\n",
    "//----------------------- Select Landsat imagery by time and location -----------------------\n",
    "\n",
    "var imagery = ee.ImageCollection(ImCol);\n",
    "\n",
    "// In the following lines imagery will be collected in an ImageCollection, depending on the\n",
    "// location of our study area, a given time frame and the ratio of cloud cover.\n",
    "var prefireImCol = ee.ImageCollection(imagery\n",
    "    // Filter by dates.\n",
    "    .filterDate(prefire_start, prefire_end)\n",
    "    // Filter by location.\n",
    "    .filterBounds(area)\n",
    "    .sort('CLOUD_COVER'));\n",
    "    \n",
    "// Select all images that overlap with the study area from a given time frame \n",
    "// As a post-fire state we select the 25th of February 2017\n",
    "var postfireImCol = ee.ImageCollection(imagery\n",
    "    // Filter by dates.\n",
    "    .filterDate(postfire_start, postfire_end)\n",
    "    // Filter by location.\n",
    "    .filterBounds(area)\n",
    "    .sort('CLOUD_COVER'));\n",
    "\n",
    "// Add the clipped images to the console on the right\n",
    "print(\"Pre-fire Image Collection: \", prefireImCol); \n",
    "print(\"Post-fire Image Collection: \", postfireImCol);\n",
    "\n",
    "//------------------------------- Apply a cloud and snow mask -------------------------------\n",
    "\n",
    "// Function to mask clouds from the pixel quality band of Sentinel-2 SR data.\n",
    "function maskS2sr(image) {\n",
    "  // Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  var cloudBitMask = ee.Number(2).pow(10).int();\n",
    "  var cirrusBitMask = ee.Number(2).pow(11).int();\n",
    "  // Get the pixel QA band.\n",
    "  var qa = image.select('QA60');\n",
    "  // All flags should be set to zero, indicating clear conditions.\n",
    "  var mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
    "      .and(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
    "  // Return the masked image, scaled to TOA reflectance, without the QA bands.\n",
    "  return image.updateMask(mask)\n",
    "      .copyProperties(image, [\"system:time_start\"]);\n",
    "}\n",
    "\n",
    "// Function to mask clouds from the pixel quality band of Landsat 8 SR data.\n",
    "function maskL8sr(image) {\n",
    "  // Bits 3 and 5 are cloud shadow and cloud, respectively.\n",
    "  var cloudShadowBitMask = 1 << 3;\n",
    "  var cloudsBitMask = 1 << 5;\n",
    "  var snowBitMask = 1 << 4;\n",
    "  // Get the pixel QA band.\n",
    "  var qa = image.select('pixel_qa');\n",
    "  // All flags should be set to zero, indicating clear conditions.\n",
    "  var mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0)\n",
    "      .and(qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "      .and(qa.bitwiseAnd(snowBitMask).eq(0));\n",
    "  // Return the masked image, scaled to TOA reflectance, without the QA bands.\n",
    "  return image.updateMask(mask)\n",
    "      .select(\"B[0-9]*\")\n",
    "      .copyProperties(image, [\"system:time_start\"]);\n",
    "}\n",
    "\n",
    "// Apply platform-specific cloud mask\n",
    "if (platform == 'S2' | platform == 's2') {\n",
    "  var prefire_CM_ImCol = prefireImCol.map(maskS2sr);\n",
    "  var postfire_CM_ImCol = postfireImCol.map(maskS2sr);\n",
    "} else {\n",
    "  var prefire_CM_ImCol = prefireImCol.map(maskL8sr);\n",
    "  var postfire_CM_ImCol = postfireImCol.map(maskL8sr);\n",
    "}\n",
    "\n",
    "//----------------------- Mosaic and clip images to study area -----------------------------\n",
    "\n",
    "// This is especially important, if the collections created above contain more than one image\n",
    "// (if it is only one, the mosaic() does not affect the imagery).\n",
    "\n",
    "var pre_mos = prefireImCol.mosaic().clip(area);\n",
    "var post_mos = postfireImCol.mosaic().clip(area);\n",
    "\n",
    "var pre_cm_mos = prefire_CM_ImCol.mosaic().clip(area);\n",
    "var post_cm_mos = postfire_CM_ImCol.mosaic().clip(area);\n",
    "\n",
    "// Add the clipped images to the console on the right\n",
    "print(\"Pre-fire True Color Image: \", pre_mos); \n",
    "print(\"Post-fire True Color Image: \", post_mos);\n",
    "\n",
    "//------------------ Calculate NBR for pre- and post-fire images ---------------------------\n",
    "\n",
    "// Apply platform-specific NBR = (NIR-SWIR2) / (NIR+SWIR2)\n",
    "if (platform == 'S2' | platform == 's2') {\n",
    "  var preNBR = pre_cm_mos.normalizedDifference(['B8', 'B12']);\n",
    "  var postNBR = post_cm_mos.normalizedDifference(['B8', 'B12']);\n",
    "} else {\n",
    "  var preNBR = pre_cm_mos.normalizedDifference(['B5', 'B7']);\n",
    "  var postNBR = post_cm_mos.normalizedDifference(['B5', 'B7']);\n",
    "}\n",
    "\n",
    "\n",
    "// Add the NBR images to the console on the right\n",
    "//print(\"Pre-fire Normalized Burn Ratio: \", preNBR); \n",
    "//print(\"Post-fire Normalized Burn Ratio: \", postNBR);\n",
    "\n",
    "//------------------ Calculate difference between pre- and post-fire images ----------------\n",
    "\n",
    "// The result is called delta NBR or dNBR\n",
    "var dNBR_unscaled = preNBR.subtract(postNBR);\n",
    "\n",
    "// Scale product to USGS standards\n",
    "var dNBR = dNBR_unscaled.multiply(1000);\n",
    "\n",
    "// Add the difference image to the console on the right\n",
    "print(\"Difference Normalized Burn Ratio: \", dNBR);\n",
    "\n",
    "//==========================================================================================\n",
    "//                                    ADD LAYERS TO MAP\n",
    "\n",
    "// Add boundary.\n",
    "Map.addLayer(area.draw({color: 'ffffff', strokeWidth: 5}), {},'Study Area');\n",
    "\n",
    "//---------------------------------- True Color Imagery ------------------------------------\n",
    "\n",
    "// Apply platform-specific visualization parameters for true color images\n",
    "if (platform == 'S2' | platform == 's2') {\n",
    "  var vis = {bands: ['B4', 'B3', 'B2'], max: 2000, gamma: 1.5};\n",
    "} else {\n",
    "  var vis = {bands: ['B4', 'B3', 'B2'], min: 0, max: 4000, gamma: 1.5};\n",
    "}\n",
    "\n",
    "// Add the true color images to the map.\n",
    "Map.addLayer(pre_mos, vis,'Pre-fire image');\n",
    "Map.addLayer(post_mos, vis,'Post-fire image');\n",
    "\n",
    "// Add the true color images to the map.\n",
    "Map.addLayer(pre_cm_mos, vis,'Pre-fire True Color Image - Clouds masked');\n",
    "Map.addLayer(post_cm_mos, vis,'Post-fire True Color Image - Clouds masked');\n",
    "\n",
    "//--------------------------- Burn Ratio Product - Greyscale -------------------------------\n",
    "\n",
    "var grey = ['white', 'black'];\n",
    "\n",
    "// Remove comment-symbols (//) below to display pre- and post-fire NBR seperately\n",
    "//Map.addLayer(preNBR, {min: -1, max: 1, palette: grey}, 'Prefire Normalized Burn Ratio');\n",
    "//Map.addLayer(postNBR, {min: -1, max: 1, palette: grey}, 'Postfire Normalized Burn Ratio');\n",
    "\n",
    "Map.addLayer(dNBR, {min: -1000, max: 1000, palette: grey}, 'dNBR greyscale');\n",
    "\n",
    "//------------------------- Burn Ratio Product - Classification ----------------------------\n",
    "\n",
    "// Define an SLD style of discrete intervals to apply to the image.\n",
    "var sld_intervals =\n",
    "  '<RasterSymbolizer>' +\n",
    "    '<ColorMap type=\"intervals\" extended=\"false\" >' +\n",
    "      '<ColorMapEntry color=\"#ffffff\" quantity=\"-500\" label=\"-500\"/>' +\n",
    "      '<ColorMapEntry color=\"#7a8737\" quantity=\"-250\" label=\"-250\" />' +\n",
    "      '<ColorMapEntry color=\"#acbe4d\" quantity=\"-100\" label=\"-100\" />' +\n",
    "      '<ColorMapEntry color=\"#0ae042\" quantity=\"100\" label=\"100\" />' +\n",
    "      '<ColorMapEntry color=\"#fff70b\" quantity=\"270\" label=\"270\" />' +\n",
    "      '<ColorMapEntry color=\"#ffaf38\" quantity=\"440\" label=\"440\" />' +\n",
    "      '<ColorMapEntry color=\"#ff641b\" quantity=\"660\" label=\"660\" />' +\n",
    "      '<ColorMapEntry color=\"#a41fd6\" quantity=\"2000\" label=\"2000\" />' +\n",
    "    '</ColorMap>' +\n",
    "  '</RasterSymbolizer>';\n",
    "\n",
    "// Add the image to the map using both the color ramp and interval schemes.\n",
    "Map.addLayer(dNBR.sldStyle(sld_intervals), {}, 'dNBR classified');\n",
    "\n",
    "// Seperate result into 8 burn severity classes\n",
    "var thresholds = ee.Image([-1000, -251, -101, 99, 269, 439, 659, 2000]);\n",
    "var classified = dNBR.lt(thresholds).reduce('sum').toInt();\n",
    "\n",
    "//==========================================================================================\n",
    "//                              ADD BURNED AREA STATISTICS\n",
    "\n",
    "// count number of pixels in entire layer\n",
    "var allpix =  classified.updateMask(classified);  // mask the entire layer\n",
    "var pixstats = allpix.reduceRegion({\n",
    "  reducer: ee.Reducer.count(),               // count pixels in a single class\n",
    "  geometry: area,\n",
    "  scale: 30\n",
    "  });\n",
    "var allpixels = ee.Number(pixstats.get('sum')); // extract pixel count as a number\n",
    "\n",
    "\n",
    "// create an empty list to store area values in\n",
    "var arealist = [];\n",
    "\n",
    "// create a function to derive extent of one burn severity class\n",
    "// arguments are class number and class name\n",
    "var areacount = function(cnr, name) {\n",
    " var singleMask =  classified.updateMask(classified.eq(cnr));  // mask a single class\n",
    " var stats = singleMask.reduceRegion({\n",
    "  reducer: ee.Reducer.count(),               // count pixels in a single class\n",
    "  geometry: area,\n",
    "  scale: 30\n",
    "  });\n",
    "var pix =  ee.Number(stats.get('sum'));\n",
    "var hect = pix.multiply(900).divide(10000);                // Landsat pixel = 30m x 30m --> 900 sqm\n",
    "var perc = pix.divide(allpixels).multiply(10000).round().divide(100);   // get area percent by class and round to 2 decimals\n",
    "arealist.push({Class: name, Pixels: pix, Hectares: hect, Percentage: perc});\n",
    "};\n",
    "\n",
    "// severity classes in different order\n",
    "var names2 = ['NA', 'High Severity', 'Moderate-high Severity',\n",
    "'Moderate-low Severity', 'Low Severity','Unburned', 'Enhanced Regrowth, Low', 'Enhanced Regrowth, High'];\n",
    "\n",
    "// execute function for each class\n",
    "for (var i = 0; i < 8; i++) {\n",
    "  areacount(i, names2[i]);\n",
    "  }\n",
    "\n",
    "print('Burned Area by Severity Class', arealist, '--> click list objects for individual classes');\n",
    "\n",
    "//==========================================================================================\n",
    "//                                    ADD A LEGEND\n",
    "\n",
    "// set position of panel\n",
    "var legend = ui.Panel({\n",
    "  style: {\n",
    "    position: 'bottom-left',\n",
    "    padding: '8px 15px'\n",
    "  }});\n",
    " \n",
    "// Create legend title\n",
    "var legendTitle = ui.Label({\n",
    "  value: 'dNBR Classes',\n",
    "  style: {fontWeight: 'bold',\n",
    "    fontSize: '18px',\n",
    "    margin: '0 0 4px 0',\n",
    "    padding: '0'\n",
    "    }});\n",
    " \n",
    "// Add the title to the panel\n",
    "legend.add(legendTitle);\n",
    " \n",
    "// Creates and styles 1 row of the legend.\n",
    "var makeRow = function(color, name) {\n",
    " \n",
    "      // Create the label that is actually the colored box.\n",
    "      var colorBox = ui.Label({\n",
    "        style: {\n",
    "          backgroundColor: '#' + color,\n",
    "          // Use padding to give the box height and width.\n",
    "          padding: '8px',\n",
    "          margin: '0 0 4px 0'\n",
    "        }});\n",
    " \n",
    "      // Create the label filled with the description text.\n",
    "      var description = ui.Label({\n",
    "        value: name,\n",
    "        style: {margin: '0 0 4px 6px'}\n",
    "      });\n",
    " \n",
    "      // return the panel\n",
    "      return ui.Panel({\n",
    "        widgets: [colorBox, description],\n",
    "        layout: ui.Panel.Layout.Flow('horizontal')\n",
    "      })};\n",
    " \n",
    "//  Palette with the colors\n",
    "var palette =['7a8737', 'acbe4d', '0ae042', 'fff70b', 'ffaf38', 'ff641b', 'a41fd6', 'ffffff'];\n",
    " \n",
    "// name of the legend\n",
    "var names = ['Enhanced Regrowth, High','Enhanced Regrowth, Low','Unburned', 'Low Severity',\n",
    "'Moderate-low Severity', 'Moderate-high Severity', 'High Severity', 'NA'];\n",
    " \n",
    "// Add color and and names\n",
    "for (var i = 0; i < 8; i++) {\n",
    "  legend.add(makeRow(palette[i], names[i]));\n",
    "  }  \n",
    " \n",
    "// add legend to map (alternatively you can also print the legend to the console)\n",
    "Map.add(legend);\n",
    "\n",
    "//==========================================================================================\n",
    "//                                  PREPARE FILE EXPORT\n",
    "\n",
    "var id = dNBR.id().getInfo();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
